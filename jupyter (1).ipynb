{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "31d9a4c9",
      "metadata": {
        "origin_pos": 0,
        "id": "31d9a4c9"
      },
      "source": [
        "# Using Jupyter Notebooks\n",
        ":label:`sec_jupyter`\n",
        "\n",
        "\n",
        "This section describes how to edit and run the code\n",
        "in each section of this book\n",
        "using the Jupyter Notebook. Make sure you have\n",
        "installed Jupyter and downloaded the\n",
        "code as described in\n",
        ":ref:`chap_installation`.\n",
        "If you want to know more about Jupyter see the excellent tutorial in\n",
        "their [documentation](https://jupyter.readthedocs.io/en/latest/).\n",
        "\n",
        "\n",
        "## Editing and Running the Code Locally\n",
        "\n",
        "Suppose that the local path of the book's code is `xx/yy/d2l-en/`. Use the shell to change the directory to this path (`cd xx/yy/d2l-en`) and run the command `jupyter notebook`. If your browser does not do this automatically, open http://localhost:8888 and you will see the interface of Jupyter and all the folders containing the code of the book, as shown in :numref:`fig_jupyter00`.\n",
        "\n",
        "![The folders containing the code of this book.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter00.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter00`\n",
        "\n",
        "\n",
        "You can access the notebook files by clicking on the folder displayed on the webpage.\n",
        "They usually have the suffix \".ipynb\".\n",
        "For the sake of brevity, we create a temporary \"test.ipynb\" file.\n",
        "The content displayed after you click it is\n",
        "shown in :numref:`fig_jupyter01`.\n",
        "This notebook includes a markdown cell and a code cell. The content in the markdown cell includes \"This Is a Title\" and \"This is text.\".\n",
        "The code cell contains two lines of Python code.\n",
        "\n",
        "![Markdown and code cells in the \"text.ipynb\" file.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter01.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter01`\n",
        "\n",
        "\n",
        "Double click on the markdown cell to enter edit mode.\n",
        "Add a new text string \"Hello world.\" at the end of the cell, as shown in :numref:`fig_jupyter02`.\n",
        "\n",
        "![Edit the markdown cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter02.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter02`\n",
        "\n",
        "\n",
        "As demonstrated in :numref:`fig_jupyter03`,\n",
        "click \"Cell\" $\\rightarrow$ \"Run Cells\" in the menu bar to run the edited cell.\n",
        "\n",
        "![Run the cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter03.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter03`\n",
        "\n",
        "After running, the markdown cell is shown in :numref:`fig_jupyter04`.\n",
        "\n",
        "![The markdown cell after running.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter04.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter04`\n",
        "\n",
        "\n",
        "Next, click on the code cell. Multiply the elements by 2 after the last line of code, as shown in :numref:`fig_jupyter05`.\n",
        "\n",
        "![Edit the code cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter05.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter05`\n",
        "\n",
        "\n",
        "You can also run the cell with a shortcut (\"Ctrl + Enter\" by default) and obtain the output result from :numref:`fig_jupyter06`.\n",
        "\n",
        "![Run the code cell to obtain the output.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter06.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter06`\n",
        "\n",
        "\n",
        "When a notebook contains more cells, we can click \"Kernel\" $\\rightarrow$ \"Restart & Run All\" in the menu bar to run all the cells in the entire notebook. By clicking \"Help\" $\\rightarrow$ \"Edit Keyboard Shortcuts\" in the menu bar, you can edit the shortcuts according to your preferences.\n",
        "\n",
        "## Advanced Options\n",
        "\n",
        "Beyond local editing two things are quite important: editing the notebooks in the markdown format and running Jupyter remotely.\n",
        "The latter matters when we want to run the code on a faster server.\n",
        "The former matters since Jupyter's native ipynb format stores a lot of auxiliary data that is\n",
        "irrelevant to the content,\n",
        "mostly related to how and where the code is run.\n",
        "This is confusing for Git, making\n",
        "reviewing contributions very difficult.\n",
        "Fortunately there is an alternative---native editing in the markdown format.\n",
        "\n",
        "### Markdown Files in Jupyter\n",
        "\n",
        "If you wish to contribute to the content of this book, you need to modify the\n",
        "source file (md file, not ipynb file) on GitHub.\n",
        "Using the notedown plugin we\n",
        "can modify notebooks in the md format directly in Jupyter.\n",
        "\n",
        "\n",
        "First, install the notedown plugin, run the Jupyter Notebook, and load the plugin:\n",
        "\n",
        "```\n",
        "pip install d2l-notedown  # You may need to uninstall the original notedown.\n",
        "jupyter notebook --NotebookApp.contents_manager_class='notedown.NotedownContentsManager'\n",
        "```\n",
        "\n",
        "You may also turn on the notedown plugin by default whenever you run the Jupyter Notebook.\n",
        "First, generate a Jupyter Notebook configuration file (if it has already been generated, you can skip this step).\n",
        "\n",
        "```\n",
        "jupyter notebook --generate-config\n",
        "```\n",
        "\n",
        "Then, add the following line to the end of the Jupyter Notebook configuration file (for Linux or macOS, usually in the path `~/.jupyter/jupyter_notebook_config.py`):\n",
        "\n",
        "```\n",
        "c.NotebookApp.contents_manager_class = 'notedown.NotedownContentsManager'\n",
        "```\n",
        "\n",
        "After that, you only need to run the `jupyter notebook` command to turn on the notedown plugin by default.\n",
        "\n",
        "### Running Jupyter Notebooks on a Remote Server\n",
        "\n",
        "Sometimes, you may want to run Jupyter notebooks on a remote server and access it through a browser on your local computer. If Linux or macOS is installed on your local machine (Windows can also support this function through third-party software such as PuTTY), you can use port forwarding:\n",
        "\n",
        "```\n",
        "ssh myserver -L 8888:localhost:8888\n",
        "```\n",
        "\n",
        "The above string `myserver` is the address of the remote server.\n",
        "Then we can use http://localhost:8888 to access the remote server `myserver` that runs Jupyter notebooks. We will detail on how to run Jupyter notebooks on AWS instances\n",
        "later in this appendix.\n",
        "\n",
        "### Timing\n",
        "\n",
        "We can use the `ExecuteTime` plugin to time the execution of each code cell in Jupyter notebooks.\n",
        "Use the following commands to install the plugin:\n",
        "\n",
        "```\n",
        "pip install jupyter_contrib_nbextensions\n",
        "jupyter contrib nbextension install --user\n",
        "jupyter nbextension enable execute_time/ExecuteTime\n",
        "```\n",
        "\n",
        "## Summary\n",
        "\n",
        "* Using the Jupyter Notebook tool, we can edit, run, and contribute to each section of the book.\n",
        "* We can run Jupyter notebooks on remote servers using port forwarding.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Edit and run the code in this book with the Jupyter Notebook on your local machine.\n",
        "1. Edit and run the code in this book with the Jupyter Notebook *remotely* via port forwarding.\n",
        "1. Compare the running time of the operations $\\mathbf{A}^\\top \\mathbf{B}$ and $\\mathbf{A} \\mathbf{B}$ for two square matrices in $\\mathbb{R}^{1024 \\times 1024}$. Which one is faster?\n",
        "\n",
        "\n",
        "[Discussions](https://discuss.d2l.ai/t/421)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MLflow if not already installed\n",
        "!pip install -q mlflow\n",
        "\n",
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pickle  # for saving as .pkl\n",
        "\n",
        "# Load Data\n",
        "data = pd.read_csv('/content/parkinsons.data')\n",
        "\n",
        "# Explore Data\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "\n",
        "# Separate Features and Target\n",
        "X = data.drop(columns=['name', 'status'])  # 'name' is irrelevant\n",
        "y = data['status']  # 0 = healthy, 1 = Parkinson's\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Save Scaler as pickle file\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print(\"Scaler saved as scaler.pkl\")\n",
        "\n",
        "# MLflow Tracking\n",
        "mlflow.set_experiment(\"Parkinsons-MLP-Experiment\")\n",
        "\n",
        "with mlflow.start_run():\n",
        "\n",
        "    # Build MLP Model\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')  # Binary classification\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred_probs = model.predict(X_test_scaled)\n",
        "    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Log parameters, metrics, and model\n",
        "    mlflow.log_param(\"optimizer\", \"adam\")\n",
        "    mlflow.log_param(\"epochs\", 50)\n",
        "    mlflow.log_param(\"batch_size\", 16)\n",
        "    mlflow.log_metric(\"accuracy\", acc)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "\n",
        "    mlflow.sklearn.log_model(scaler, \"scaler\")\n",
        "    mlflow.keras.log_model(model, \"MLP_Model\")\n",
        "\n",
        "    # Save Keras model as pickle (special method)\n",
        "    model.save('mlp_model.h5')\n",
        "    print(\"Model saved as mlp_model.h5\")\n",
        "\n",
        "print(\"Run completed and logged in MLflow.\")\n"
      ],
      "metadata": {
        "id": "plpCaQb1lM2z",
        "outputId": "30088a47-a929-41b8-ca88-28d07d62e782",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "plpCaQb1lM2z",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
            "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
            "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
            "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
            "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
            "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
            "\n",
            "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
            "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
            "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
            "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
            "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
            "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
            "\n",
            "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
            "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
            "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
            "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
            "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
            "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
            "\n",
            "    spread2        D2       PPE  \n",
            "0  0.266482  2.301442  0.284654  \n",
            "1  0.335590  2.486855  0.368674  \n",
            "2  0.311173  2.342259  0.332634  \n",
            "3  0.334147  2.405554  0.368975  \n",
            "4  0.234513  2.332180  0.410335  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 195 entries, 0 to 194\n",
            "Data columns (total 24 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   name              195 non-null    object \n",
            " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
            " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
            " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
            " 4   MDVP:Jitter(%)    195 non-null    float64\n",
            " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
            " 6   MDVP:RAP          195 non-null    float64\n",
            " 7   MDVP:PPQ          195 non-null    float64\n",
            " 8   Jitter:DDP        195 non-null    float64\n",
            " 9   MDVP:Shimmer      195 non-null    float64\n",
            " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
            " 11  Shimmer:APQ3      195 non-null    float64\n",
            " 12  Shimmer:APQ5      195 non-null    float64\n",
            " 13  MDVP:APQ          195 non-null    float64\n",
            " 14  Shimmer:DDA       195 non-null    float64\n",
            " 15  NHR               195 non-null    float64\n",
            " 16  HNR               195 non-null    float64\n",
            " 17  status            195 non-null    int64  \n",
            " 18  RPDE              195 non-null    float64\n",
            " 19  DFA               195 non-null    float64\n",
            " 20  spread1           195 non-null    float64\n",
            " 21  spread2           195 non-null    float64\n",
            " 22  D2                195 non-null    float64\n",
            " 23  PPE               195 non-null    float64\n",
            "dtypes: float64(22), int64(1), object(1)\n",
            "memory usage: 36.7+ KB\n",
            "None\n",
            "Scaler saved as scaler.pkl\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.4827 - loss: 0.7048 - val_accuracy: 0.6562 - val_loss: 0.5652\n",
            "Epoch 2/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8043 - loss: 0.5636 - val_accuracy: 0.8125 - val_loss: 0.4619\n",
            "Epoch 3/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8978 - loss: 0.4551 - val_accuracy: 0.8438 - val_loss: 0.4076\n",
            "Epoch 4/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8899 - loss: 0.3935 - val_accuracy: 0.8438 - val_loss: 0.3769\n",
            "Epoch 5/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9040 - loss: 0.3701 - val_accuracy: 0.8438 - val_loss: 0.3560\n",
            "Epoch 6/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9118 - loss: 0.3216 - val_accuracy: 0.8750 - val_loss: 0.3393\n",
            "Epoch 7/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8859 - loss: 0.3223 - val_accuracy: 0.8438 - val_loss: 0.3237\n",
            "Epoch 8/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9097 - loss: 0.3030 - val_accuracy: 0.8438 - val_loss: 0.3112\n",
            "Epoch 9/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9338 - loss: 0.2408 - val_accuracy: 0.8438 - val_loss: 0.3008\n",
            "Epoch 10/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9069 - loss: 0.2644 - val_accuracy: 0.8438 - val_loss: 0.2907\n",
            "Epoch 11/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9034 - loss: 0.2552 - val_accuracy: 0.8438 - val_loss: 0.2826\n",
            "Epoch 12/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9060 - loss: 0.2353 - val_accuracy: 0.8750 - val_loss: 0.2719\n",
            "Epoch 13/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8946 - loss: 0.2434 - val_accuracy: 0.8750 - val_loss: 0.2630\n",
            "Epoch 14/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9073 - loss: 0.2405 - val_accuracy: 0.8750 - val_loss: 0.2542\n",
            "Epoch 15/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9113 - loss: 0.2267 - val_accuracy: 0.8750 - val_loss: 0.2469\n",
            "Epoch 16/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9191 - loss: 0.1929 - val_accuracy: 0.8750 - val_loss: 0.2422\n",
            "Epoch 17/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9413 - loss: 0.1700 - val_accuracy: 0.8750 - val_loss: 0.2389\n",
            "Epoch 18/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9678 - loss: 0.1414 - val_accuracy: 0.8750 - val_loss: 0.2377\n",
            "Epoch 19/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9209 - loss: 0.1788 - val_accuracy: 0.8750 - val_loss: 0.2312\n",
            "Epoch 20/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9424 - loss: 0.1621 - val_accuracy: 0.8750 - val_loss: 0.2251\n",
            "Epoch 21/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9347 - loss: 0.1649 - val_accuracy: 0.8750 - val_loss: 0.2201\n",
            "Epoch 22/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9544 - loss: 0.1239 - val_accuracy: 0.8750 - val_loss: 0.2235\n",
            "Epoch 23/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9331 - loss: 0.1671 - val_accuracy: 0.8750 - val_loss: 0.2211\n",
            "Epoch 24/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9418 - loss: 0.1467 - val_accuracy: 0.9062 - val_loss: 0.2128\n",
            "Epoch 25/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9804 - loss: 0.1083 - val_accuracy: 0.8750 - val_loss: 0.2141\n",
            "Epoch 26/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9848 - loss: 0.1248 - val_accuracy: 0.8750 - val_loss: 0.2160\n",
            "Epoch 27/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9816 - loss: 0.1284 - val_accuracy: 0.8750 - val_loss: 0.2147\n",
            "Epoch 28/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9746 - loss: 0.1139 - val_accuracy: 0.8750 - val_loss: 0.2135\n",
            "Epoch 29/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9825 - loss: 0.0937 - val_accuracy: 0.9375 - val_loss: 0.2062\n",
            "Epoch 30/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9634 - loss: 0.1242 - val_accuracy: 0.8750 - val_loss: 0.2101\n",
            "Epoch 31/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0970 - val_accuracy: 0.8750 - val_loss: 0.2120\n",
            "Epoch 32/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9901 - loss: 0.0924 - val_accuracy: 0.9375 - val_loss: 0.2055\n",
            "Epoch 33/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9783 - loss: 0.0997 - val_accuracy: 0.9375 - val_loss: 0.2057\n",
            "Epoch 34/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9943 - loss: 0.0831 - val_accuracy: 0.9062 - val_loss: 0.2122\n",
            "Epoch 35/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9812 - loss: 0.0960 - val_accuracy: 0.9062 - val_loss: 0.2060\n",
            "Epoch 36/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9907 - loss: 0.0713 - val_accuracy: 0.9062 - val_loss: 0.2103\n",
            "Epoch 37/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9858 - loss: 0.0710 - val_accuracy: 0.9062 - val_loss: 0.2118\n",
            "Epoch 38/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9854 - loss: 0.0742 - val_accuracy: 0.9062 - val_loss: 0.2159\n",
            "Epoch 39/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9750 - loss: 0.0672 - val_accuracy: 0.9375 - val_loss: 0.2017\n",
            "Epoch 40/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9756 - loss: 0.0721 - val_accuracy: 0.9062 - val_loss: 0.2069\n",
            "Epoch 41/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9672 - loss: 0.0751 - val_accuracy: 0.9062 - val_loss: 0.2127\n",
            "Epoch 42/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9943 - loss: 0.0520 - val_accuracy: 0.9062 - val_loss: 0.2222\n",
            "Epoch 43/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9982 - loss: 0.0472 - val_accuracy: 0.9375 - val_loss: 0.2040\n",
            "Epoch 44/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 0.0517 - val_accuracy: 0.9062 - val_loss: 0.2133\n",
            "Epoch 45/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9929 - loss: 0.0444 - val_accuracy: 0.9062 - val_loss: 0.2190\n",
            "Epoch 46/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0453 - val_accuracy: 0.9062 - val_loss: 0.2195\n",
            "Epoch 47/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9375 - val_loss: 0.2096\n",
            "Epoch 48/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9982 - loss: 0.0430 - val_accuracy: 0.9062 - val_loss: 0.2133\n",
            "Epoch 49/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9972 - loss: 0.0361 - val_accuracy: 0.9062 - val_loss: 0.2240\n",
            "Epoch 50/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0366 - val_accuracy: 0.9062 - val_loss: 0.2233\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "Accuracy:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/04/28 08:48:33 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.9487179487179487\n",
            "F1 Score: 0.9696969696969697\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.71      0.83         7\n",
            "           1       0.94      1.00      0.97        32\n",
            "\n",
            "    accuracy                           0.95        39\n",
            "   macro avg       0.97      0.86      0.90        39\n",
            "weighted avg       0.95      0.95      0.95        39\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/04/28 08:48:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "2025/04/28 08:48:38 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
            "\u001b[31m2025/04/28 08:48:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as mlp_model.h5\n",
            "Run completed and logged in MLflow.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}